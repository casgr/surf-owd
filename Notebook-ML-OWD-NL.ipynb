{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron - MNIST\n",
    "\n",
    "Tijdens het praktische gedeelte van deze sessie gaan we aan de slag met Jupyter notebooks. Een notebook is een gebruiksvriendelijke manier om code te schrijven in de programmeertaal Python. De indeling van de notebooks werkt als volgt:\n",
    "\n",
    "- Elke rechthoekige \"__cel__\" in de notebook bevat een toelichting (\"__Markdown__\", net zoals deze cel) of Python-commando's (\"__Code__\"). Selecteer een cel door er 1 keer op te klikken.\n",
    "\n",
    "\n",
    "- Door op de knop \"__Run__\" te klikken, wordt de huidig geselecteerde cel uitgevoerd en de volgende cel geselecteerd. Wanneer een cel commando's bevat, worden de resultaten hiervan na uitvoer onder de cel weergegeven.\n",
    "\n",
    "\n",
    "Probeer op deze wijze door het notebook heen te werken. Laat je niet afschrikken door de code, in principe is alles al ingevuld. \n",
    "###### Let op: wanneer er iets fout gaat en je de notebook wilt herstarten, dien je weer bovenaan te beginnen!\n",
    "\n",
    "Laten we starten met het importeren van de vereiste plugins. Voer de cel uit, en controleer of er een boodschap onder de cel verschijnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, keras\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "keras.initializers.RandomNormal(seed=42)\n",
    "print(\"Klaar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doel van deze notebook is het trainen van 10 __perceptrons__. Kortgezegd is een perceptron een simpel neuraal netwerk, bestaande uit een $X$ aantal __inputs__. Alle inputs zijn verbonden met een __output__. De verbindingen tussen $X$ en deze outputs, die de __gewichten__ worden genoemd, worden getraind om te zorgen dat de juiste output wordt geactiveerd wanneer de input bepaalde patronen bevat.\n",
    "\n",
    "Tijdens dit experiment trainen we 10 perceptrons tegelijkertijd op dezelfde invoer, met als doel __automatisch handgeschreven nummers te herkennen__ ('0' tot '9'). Elke perceptron krijgt als taak om een van de getallen te herkennen; afhankelijk van hoe 'sterk' het netwerk een getal denkt te herkennen wordt de perceptron van het respectievelijke getal geactiveerd. Elke output genereert op deze manier een 'kans'-waarde, hoe hoger deze waarde, hoe zekerder het netwerk is van zijn classificatie. De output met de hoogste waarde is de classificatie van de input.\n",
    "\n",
    "<img src=\"images/Perceptron2.png\" alt=\"Perceptron visualization\" style=\"width: 400px;\"/>\n",
    "\n",
    ">_Illustratie van de 10 perceptrons._\n",
    "\n",
    "We gaan de perceptrons trainen op de breed toegepaste MNIST-dataset, die tienduizenden afbeeldingen van handgeschreven nummers bevat. Elke nummer bestaat uit een zwart-wit plaatje met een resolutie van 28 x 28 pixels. Ieder plaatje is van een label voorzien, en op die manier toegewezen aan een van de 10 categorieen ('0', '1', .... '9'). \n",
    "\n",
    "Om de plaatjes te kunnen verwerken in dit neurale netwerk, worden ze 'platgeslagen'. De afbeelding van 28 x 28 pixels wordt omgezet naar een rij van 28*28=784 getallen. De $X$-waarde van ons neurale netwerk is dus 784.\n",
    "\n",
    "De MNIST-dataset bestaat uit zowel een training- en test-dataset. Een vuistregel voor experimenten met neurale netwerken is om een deel van de beschikbare data apart te zetten in een test-dataset, geschikt voor validatiedoeleinden. Op deze manier kunnen we de nauwkeurigheid van ons neurale netwerk bij gebruik van nieuwe data valideren. Uiteraard zijn alletwee de datasets ook van een lijst met corresponderende labels voorzien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print('MNIST data is geimporteerd.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De perceptrons worden straks getraind op de plaatjes uit de __training-dataset__, door ze samen met de __training-labels__ door het neurale netwerk te laten verwerken. \n",
    "\n",
    "Laten we bekijken hoe de training-dataset in elkaar zit. Als het goed is laat de code hieronder zien dat er 60.000 plaatjes in de dataset zitten, met een resolutie van 28 x 28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klopt helemaal! Laten we eens kijken hoe de eerste 5 plaatjes uit de dataset eruit zien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(241)\n",
    "plt.imshow(train_images[10].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(242)\n",
    "plt.imshow(train_images[1].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(243)\n",
    "plt.imshow(train_images[2].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(244)\n",
    "plt.imshow(train_images[3].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(245)\n",
    "plt.imshow(train_images[4].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(246)\n",
    "plt.imshow(train_images[5].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(247)\n",
    "plt.imshow(train_images[6].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(248)\n",
    "plt.imshow(train_images[7].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dat ziet er goed uit. We hebben natuurlijk ook de labels bij de plaatjes nodig. Het aantal labels zou gelijk moeten zijn aan het aantal plaatjes (60.000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoeveel unieke labels zijn er? Dit zouden er '0' tot '9' moeten zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zijn de labels (ongeveer) gebalanceerd? Klopt het dat er ongeveer evenveel plaatjes per categorie in de training-dataset zitten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_labels)\n",
    "\n",
    "plt.title(\"Train Label Histogram\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Aantal\")\n",
    "plt.xticks(np.arange(10))\n",
    "fig = plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen hetzelfde doen voor de __test-dataset__. Deze zou uit 10.000 plaatjes moeten bestaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met 10 verschillende __test-labels__..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En een (min of meer) gelijke verdeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_labels)\n",
    "\n",
    "plt.title(\"Test Label Histogram\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Aantal\")\n",
    "plt.xticks(np.arange(10))\n",
    "fig = plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__=====================================================================================================================__\n",
    "<b><center>Stop Hier</center></b>\n",
    "__=====================================================================================================================__\n",
    "\n",
    "Ieder neuraal netwerk is opgebouwd uit __lagen__, een onderdeel dat je zou kunnen beschouwen als een filter voor de data. Er wordt data ingevoerd, deze wordt verwerkt, en vervolgens uitgevoerd in een voor het netwerk bruikbare vorm.\n",
    "\n",
    "De lagen filteren __representaties__ uit uit de ingevoerde data -- hopenlijk representaties die ons verder kunnen helpen met ons probleem (het herkennen van hangeschreven nummers). \n",
    "\n",
    "Het grootste deel van deep learning bestaat uit het bouwen van neurale netwerken, die bestaan uit vele varianten van deze lagen. De netwerken voeren een soort \"data-destillatie\" uit, door keer op keer relevante representaties uit de data te filteren.\n",
    "\n",
    "Laten we beginnen met het bouwen van ons eigen neurale netwerk! Ons netwerk bestaat uit:\n",
    "\n",
    "- Een __invoerlaag__ met 28*28=784 inputs (elke pixel uit een plaatje is een input).\n",
    "\n",
    "\n",
    "- Een __uitvoerlaag__ met 10 outputs, voor elk getal een ('0', '1', .... '9'). De output met de hoogste waarde is de classificatie van het netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(10, use_bias='true', activation='softmax', input_shape=(28 * 28,)))\n",
    "\n",
    "print('Lagen toegevoed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lagen zijn nu toegevoegd, maar we zijn er nog niet. Om het neurale netwerk klaar te maken voor gebruik moeten er nog 3 zaken geregeld worden, voordat het netwerk kan worden __gecompileerd__.\n",
    "\n",
    "* De __optimizer__: dit mechanisme zorgt ervoor dat het netwerk zichzelf kan bijwerken op basis van de ingevoerde data en de loss-functie.\n",
    "\n",
    "\n",
    "* Een __loss-functie__: deze zorgt ervoor dat het netwerk een idee heeft van hoe goed of slecht het scoort op de training-dataset. Op deze manier kan het netwerk zichzelf bijsturen.\n",
    "\n",
    "\n",
    "* De waarden die bijgehouden gaan worden tijdens het trainen en testen. In dit geval houden we alleen rekening met de __nauwkeurigheid (accuracy)__ van het netwerk, bestaande uit het aantal plaatjes dat correct is geclassificeerd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.SGD(lr=0.01)\n",
    "\n",
    "network.compile(optimizer='sgd',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "print('Netwerk gecompileerd.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voordat het daadwerkelijke trainen van het netwerk kan beginnen, moet de data __omgevormd__ worden naar een formaat dat het neurale netwerk verwacht. Alle plaatjes worden __\"platgeslagen\"__ naar een lijst van 784 cijfers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "print('Data-verwerking afgerond.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het trainen van het netwerk gaat als volgt in zijn werk. Eerst voeren we de __training dataset__ in binnen het neurale netwerk (`train_images` en de bijbehorende `train_labels`). De perceptrons in het neurale netwerk leren op die manier via de __gewichten__ een associatie aan tussen de plaatjes en de labels. Daarna passen we de __test-dataset__ op het netwerk toe, door de `test_images` in het netwerk te laten verwerken. Daarna __verifieren__ we of de voorspellingen uit het netwerk overeenkomen met de labels uit `test_labels`.\n",
    "\n",
    "Het __trainen__ wordt gestart door de `fit`-functie van het netwerk aan te roepen. Het aantal `epochs` staat voor het aantal keer dat het netwerk door de training-dataset itereert. De `batch_size` geeft aan hoeveel plaatjes uit de dataset door het netwerk worden gebruikt om zichzelf bij te sturen. Een hogere batch size resulteert in een veel sneller neuraal netwerk, maar daardoor gaat de nauwkeurigheid ook omlaag.\n",
    "\n",
    ">_Bonus: Experimenteer met verschillende waarden voor de batch size en epochs, om te zien op welke manier de nauwkeurigheid van het neurale netwerk wordt beinvloed._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.fit(train_images, train_labels, epochs=20, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tijdens het trainen worden er twee getallen weergegeven: de `loss` van het netwerk over de training-dataset, en `acc`, de nauwkeurigheid die het neurale netwerk behaald op de training data:\n",
    "\n",
    "- De __loss__ zou zo laag mogelijk moeten zijn, deze waarde laat zien hoeveel fouten het netwerk maakt tijdens classificatie.\n",
    "\n",
    "\n",
    "- De __nauwkeurigheidswaarde__ laat zien welk percentage van de training-dataset correct geclassificeerd is. Let wel op dat het daarbij alleen nog maar om de __training__ data gaat!\n",
    "\n",
    "Om erachter te komen hoe goed de perceptrons functioneren bij nieuwe data, evalueren we de naukeurigheid op de __test__ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__=====================================================================================================================__\n",
    "<b><center>Stop hier</center></b>\n",
    "__=====================================================================================================================__\n",
    "\n",
    "Een interessante eigenschap van een perceptron (en vele andere typen neurale netwerken) die wordt toegepast op afbeeldingen, is dat we de interne staat van de perceptron na training kunnen visualiseren.\n",
    "\n",
    "Hieronder bouwen we de percpetron opnieuw op in een matrix van 28 x 28 pixels, zodat we deze visueel als een afbeelding kunnen interpreteren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W1 = network.layers[0].get_weights()[0]\n",
    "WW = W1.reshape(28,28,10)\n",
    "\n",
    "plt.subplot(2,5,1)\n",
    "plt.imshow(WW[:,:,0], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 0')\n",
    "plt.subplot(2,5,2)\n",
    "plt.imshow(WW[:,:,1], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 1')\n",
    "plt.subplot(2,5,3)\n",
    "plt.imshow(WW[:,:,2], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 2')\n",
    "plt.subplot(2,5,4)\n",
    "plt.imshow(WW[:,:,3], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 3')\n",
    "plt.subplot(2,5,5)\n",
    "plt.imshow(WW[:,:,4], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 4')\n",
    "plt.subplot(2,5,6)\n",
    "plt.imshow(WW[:,:,5], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 5')\n",
    "plt.subplot(2,5,7)\n",
    "plt.imshow(WW[:,:,6], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 6')\n",
    "plt.subplot(2,5,8)\n",
    "plt.imshow(WW[:,:,7], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 7')\n",
    "plt.subplot(2,5,9)\n",
    "plt.imshow(WW[:,:,8], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 8')\n",
    "plt.subplot(2,5,10)\n",
    "plt.imshow(WW[:,:,9], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 9')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">_Bonus: Wat zie je wanneer je de 10 visualisaties bekijkt? Waarom laat iedere perceptron dit specifieke patroon zien?_\n",
    "\n",
    "# Einde sessie hier? Foto uploaden misschien te ingewikkeld\n",
    "\n",
    "Nu het neurale netwerk getraind is, kunnen we voorspellingen gaan doen:\n",
    "\n",
    "- Schrijf een nummer op, en maak er een foto van met je smartphone.\n",
    "\n",
    "\n",
    "- Gebruik je smartphone om een vierkante uitsnede van de foto te maken.\n",
    "\n",
    "\n",
    "- Upload de foto in de map waarin ook deze notebook staat.\n",
    "\n",
    "Zodra je foto is geupload, kun je de onderstaande variabele `file` aanpassen, zodat deze dezelfde bestandsnaam heeft al de zojuist toegevoegde foto. Wanneer het niet lukt om een foto te maken kan gebruik gemaakt worden van een voorbeeldfoto -- voer dan `images/img.jpg` in als bestandsnaam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'bestandsnaam-hier.jpg'\n",
    "\n",
    "print('Bestandsnaam bijgewerkt.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wanneer alles goed is gegaan, kunnen we de foto visualiseren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(file,0)\n",
    "img = cv2.resize(img, (28, 28))\n",
    "img = (255-img)\n",
    "img = np.reshape(img, [1, 28 * 28])\n",
    "plt.imshow(img[0].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onze foto zou er nu min of meer hetzelfde uit moeten zien als de voorbeelden uit de train-dataset. Als laatste presenteren we de foto aan ons neurale netwerk, om een voorspelling te kunnen doen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Het op perceptrons gebaseerde neurale netwerk voorspelt:\", (np.argmax(network.predict(img))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was de voorspelling juist?\n",
    "\n",
    "__=====================================================================================================================__\n",
    "<b><center>Stop Hier</center></b>\n",
    "__=====================================================================================================================__\n",
    "\n",
    "Kijk niet vreemd op wanneer het netwerk niet in staat was een juiste voorspelling te doen. De perceptrons die we tot nu toe hebben gebruikt zijn een van de simpelste vormen van neurale netwerken.\n",
    "\n",
    "Laten we proberen om de afbeelding door een geavanceerder neuraal netwerk te halen. Om dit te doen moeten we de datasets opnieuw importeren en verwerken, een nieuw neuraal netwerk opzetten en het netwerk opnieuw trainen. Door de geavanceerde structuur van het onderstaande netwerk kan het langer duren om te trainen.\n",
    "\n",
    "De theorie achter het type netwerk dat we nu gaan toepassen (een convolutional neural network) valt buiten de scope van deze sessie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terwijl ons eerdere netwerk een nauwkeurigheidsscore van ongeveer 92% haalde, bereikt dit nieuwe netwerk een score van bijna 99% !\n",
    "\n",
    "Nu kunnen we opnieuw een voorspelling uitvoeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread(file,0)\n",
    "img2 = cv2.resize(img2, (28, 28))\n",
    "img2 = (255-img2)\n",
    "img2 = np.reshape(img2, [1, 28, 28, 1])\n",
    "\n",
    "print(\"Het geavanceerde neurale netwerk voorspelt:\", (np.argmax(model.predict(img2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze Jupyter notebook is gebaseerd op https://github.com/fchollet/deep-learning-with-python-notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
